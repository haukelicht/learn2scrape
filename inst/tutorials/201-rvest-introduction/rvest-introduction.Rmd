---
title: "Scraping static web pages with the `rvest` R package"
# author: "Theresa Gessler and Hauke Licht"
# date: "last updated: `r format(Sys.Date(), '%e %B %Y')`"
description: >
  Learn the basics of scraping data from static web pages 
  using the `rvest` package.
output: 
  learnr::tutorial:
    progressive: true
runtime: shiny_prerendered
---

```{r knitr, include=FALSE}
knitr::opts_chunk$set(
  # code chunk options
  echo = FALSE
  , eval = TRUE
  , warning = FALSE
  , message = FALSE
  , cached = FALSE 
)
```

```{r setup, include=FALSE}
library(learnr)
library(learn2scrape)
library(rvest)

quotepage <- system.file("extdata", "quotepage.html", package = "learn2scrape")
```


## Introduction

In this tutorial, we show how data can be scraed from static websites with the `rvest` R package. 

Imagine, we want to scrape a simple webpage.
For example [http://quotes.toscrape.com/](http://quotes.toscrape.com/){target="_blank"}, a webpage full of quotes.

Here is what we need to do:

1. load the *`rvest`* with the `library()` command (this is the package we'll use for most of our scraping)
2. to read the page into R, we need to tell R its address - please create a character vector named `url` that contains the URL 'http://quotes.toscrape.com/'
    - You can see if it worked by calling the object `url`.
3. read in and "parse" the HTML of the webpage. To tell R to read the webpage, we can use the function `read_html()`. Simply call it on the `url` object we just created!

```{r read, exercise=TRUE}
# TO DO: read the HTML code of this URL
"http://quotes.toscrape.com/"
```

##### *Trouble shooting*

The output does not look like you expected? 
Actually, the original webpage looks quite similar!
To see this, open [http://quotes.toscrape.com/](http://quotes.toscrape.com/){target="_blank"} in your web browser.
Next, have a look at the webpage source code.
Depending on the browser you are using, you can probably select 'view source' after a right-clicking the page. 
If you have trouble, [google has an up-to-date explanation](https://www.google.com/search?hl=&site=&q=how+to+view+webpage+source+code+in+browser){target="_blank"}. 

##### *Note*

Just if you were wondering: of course, we could have also skipped creating a variable with the URL. and could have instead directly applied the `read_html()` function on the string `'http://quotes.toscrape.com/'`.

## Extracting text

The function `read_html()` parses the HTML code, similar to what your browser does. 
Still, it gives us the entire source code including all HTML elements and their attributes. 

For now, we are only interested in the text of this webpage.
We can use the function `html_text()`.

Try it out: 

1. assign the parsed page to an object called 'page' 
2. call `html_text()` on 'page' and assign the result to an object called 'page_text'

```{r text, exercise=TRUE,exercise.lines=2}
url <- "http://quotes.toscrape.com/"
# TO DO: write the result of the below line to an object called 'page'
read_html(url)
# TO DO: extract the HTML text from 'page'

# TO DO: print the fist six lines of extracted text 
```



<!-- Did you find the quotes from before?  -->
Admittedly, this still looks very messy. 
Maybe you are thinking: If only there was a way to tell R to just get the text of the quotes! Luckily, there is.

## Extracting elements

The `html_elements()` command allows us to select specific elements from the HTML code. 
Please have a look at the documentation of the `html_elements()` command.

![](images/ex01-html_elements_docu.png)

The documentation tells us that we need to specify either an *Xpath* or a *CSS selector*. 
If you have not used HTML before, this might sound complicated. 

### HTML Basics

It helps to get a bit into the structure of HTML. 
Please click on [this link](https://www.w3schools.com/html/default.asp){target="_blank"} to read an introduction to HTML.

In a nutshell, HTML is a language for organizing webpage content. 

#### Tags 

**tags** are the most fundamental building blocks of HTML code.
The HTML code chunk below illustrates this:

```html
<div>
  <p>Hello!</p>
  <p>Goodbye!</p>
</div>
```

There are two types of **tags** in this code example: 'div' (division) and 'p' (paragraph) tags.
The code is organizing them so that the two 'p' elements are 'nested' in the outer 'div' element.
(The 'div' element ends only after the two 'p' elements.)

#### Attributes 

In addition to a tags, most web elements have **attributes** associated with them.
As shown below, attributes are written in `key='value'`-notation inside the leading and trailing '<' and '>' symbols

```html
<tag attribute1='a' attribute2='b'>
```

The most common attribute is the 'class' attribute. 
Classes help developers to differentiate between web elements of the same tag type.
So, for example, one 'div' element can have the class 'main', and another 'div' element the class 'extra.'

### CSS selectors 

CSS selectors are a type of *grammar* or *pattern-description* that helps us select specific elements from HTML code. 
We will speak more about CSS selectors later in the course.
For now, we will just use a tool that helps us determine the correct selectors. 
<!-- But that is not a problem: many people use these tools for scraping and only learn the basics of CSS selectors. -->

For this lesson, we will focus on two of the most important selector: tag and class selectors.

To select elements of a specific **tag*' type, just pass its name to the `css` argument of the `html_elements()` function (without the leading and trailing '<' and '>').
The CSS selector will select all elements with that tag name.

**Try it out with some of the HTML tags that we learned on the course slides.** 

<!-- As I said, we will focus more on gathering specific information but if you just want to parse large amounts of data, the universal selector can be very useful. Now, let's practice! -->

```{r select_tag,exercise=TRUE}
url <- "http://quotes.toscrape.com/"
page <- read_html(url)
# TO DO: select a specific type of HTML tag
html_elements(page, css = ...)
```

To select elements with a specific **class**, just pass the class name to the `css` argument of the `html_elements()` function with a '.' (full stop) in front.

**Try it out with some of the class you have spotted when inspecting the source code of the quotes webpage.** 

```{r select_class,exercise=TRUE}
url <- "http://quotes.toscrape.com/"
page <- read_html(url)
# TO DO: select elements with a specific class
html_elements(page, css = ...)
```

#### Extracting all vs. just one web element

You will have noticed that `html_elements()` returns *all* elements that match your query.
Use `html_element()` (singular!) To just return the first matching element.

##### *Note*

For a list of CSS Selectors, check out [this collection](https://www.w3schools.com/cssref/css_selectors.asp){target="_blank"}. 
If you want to practice CSS Selectors in a fun way, I recommend playing with the [CSS Diner](https://flukeout.github.io/){target="_blank"} where you can learn about different selector structures.

## Using SelectorGadget

While understanding HTML helps, we often do not need to engage with the code because there are lots of tools to help us. 
For example, *SelectorGadget* is a JavaScript bookmarklet that allows you to interactively figure out what CSS selector you need to extract parts of the page. 
If you have not heard of *SelectorGadget*, visit [this webpage](https://selectorgadget.com/){target="_blank"} or watch this introduction video:

![](https://vimeo.com/52055686)

We will try to use SelectorGadget now. 
If you are browsing with Google Chrome, you can [install SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb) as an extension.
If you have a different browser, drag this link into your [bookmark bar and click on it when needed](javascript:(function(){var%20s=document.createElement('div');s.innerHTML='Loading...';s.style.color='black';s.style.padding='20px';s.style.position='fixed';s.style.zIndex='9999';s.style.fontSize='3.0em';s.style.border='2px%20solid%20black';s.style.right='40px';s.style.top='40px';s.setAttribute('class','selector_gadget_loading');s.style.background='white';document.body.appendChild(s);s=document.createElement('script');s.setAttribute('type','text/javascript');s.setAttribute('src','https://dv0akt2986vzh.cloudfront.net/unstable/lib/selectorgadget.js');document.body.appendChild(s);})();).

__Try it out: Use *SelectorGadget* to select the text of all quotes on the quotes webpage.__

1. Click on the element you want to select. *SelectorGadget* will make a first guess at what CSS selector you want and mark all similar elements. It's likely to be a bad guess since it only has one example to learn from, but it's a start. Elements that match the selector will be highlighted in yellow.
2. Click on elements that shouldn't be selected. They will turn red. Click on elements that *should* be selected but are not so far. They will turn green.
3. Iterate until only the elements you want are selected. 

Of course, *SelectorGadget* is not perfect and sometimes will not be able to find a useful CSS selector. Sometimes starting from a different element helps.

**What is the selector you receive?**

```{r selector-practice, echo=FALSE}
quiz(
  caption = "Quiz about CSS selectors",
  question(
    paste(
      "Try finding the CSS selector for the text of the quote, without author and tags.",
      "What is the selector you receive?"
      ) ,
    answer(".quote", message = "Almost but we did not want to include the author and tags!"), 
    answer(".tags .tag"),
    answer(".text", correct = TRUE),
    answer("h2"),
    allow_retry = TRUE
  )
  # ,
  # question("Try finding the CSS selector for all tags associated with each quote. Deselect the Top Ten tags on the side. What is the selector you receive?",
  #   answer(".quote"),
  #   answer(".tags .tag", correct = TRUE),
  #   answer(".text"),
  #   answer("h2"),
  #   allow_retry=TRUE
  # )
)
```


### Applying CSS Selectors

Now, we try to use this CSS selector with the `html_elements()` command. 
Since each exercise chunk is independent, there will be a bit of repetition involved but it aids the memory: Parse the page, use the CSS selector to select only the quotes from the parsed HTML and assign them to a new object called 'selected_nodes'. 
Then, inspect the results by calling the object using `str()`!


```{r nodes, exercise=TRUE,exercise.setup="page-setup"}
# TO DO: extract all elements from the quotes webpage
#        that match the '.text' CSS selector
```

This already looks more structured! 
But we should get rid of the HTML tags. 
Try applying the `html_text()` command we used before to the nodes which we extracted in the last step. 
This way, we get just the text from the nodes we selected. 
You can copy the code you used to extract the nodes and continue working on that!

```{r textnodes, exercise=TRUE, exercise.setup='page-setup'}

```



## Wrap-up

**Congratulations, you scraped your first webpage!**

That was not so bad, was it?
